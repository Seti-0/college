{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin): \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # First, the prior for each \n",
    "        # distinct class 'cls' in y\n",
    "        \n",
    "        N = len(y)\n",
    "        tally = pd.Series(y).value_counts()\n",
    "        \n",
    "        self.priors = dict()\n",
    "        for cls, count in tally.items():\n",
    "            self.priors[cls] = count / N\n",
    "            \n",
    "        # Second, estimate the distribution of the \n",
    "        # likelihood for each class-value, feature-index pair.\n",
    "        \n",
    "        # More specifically, assume each is normally distributed and\n",
    "        # estimate the mean and variance of that distribution\n",
    "        \n",
    "        self.means = dict()\n",
    "        self.vars = dict()\n",
    "        \n",
    "        classes = tally.keys()\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for cls in classes:\n",
    "            \n",
    "            cls_data = X[y == cls]\n",
    "            current_means = np.zeros(n_features)\n",
    "            current_vars = np.zeros(n_features)\n",
    "            \n",
    "            for feature_index in range(n_features):\n",
    "                \n",
    "                feature_data = cls_data.transpose()[feature_index]\n",
    "                \n",
    "                mean = np.mean(feature_data)\n",
    "                var = np.var(feature_data)\n",
    "                \n",
    "                # This was an adjustment I considered that is discussed\n",
    "                # later on. It did not have the effect I expected.\n",
    "                # if var == 0:\n",
    "                #    var = max(map(abs, feature_data)) * 0.5\n",
    "                \n",
    "                current_means[feature_index] = mean\n",
    "                current_vars[feature_index] = var\n",
    "                \n",
    "            self.means[cls] = current_means\n",
    "            self.vars[cls] = current_vars\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for i, sample in enumerate(X):\n",
    "            \n",
    "            # Choose the class with the highest posterior\n",
    "            # probability.\n",
    "            \n",
    "            most_likely_cls = None\n",
    "            highest_posterior = 0\n",
    "\n",
    "            for cls, prior in self.priors.items():\n",
    "\n",
    "                likelihood = 1\n",
    "                \n",
    "                for feature_index, feature_value in enumerate(sample):\n",
    "                    \n",
    "                    mean = self.means[cls][feature_index]\n",
    "                    var = self.vars[cls][feature_index]\n",
    "                    x = feature_value\n",
    "                    \n",
    "                    if var == 0:\n",
    "                        p = 1 if x == mean else 0\n",
    "\n",
    "                    else:\n",
    "                        a = (var * 2 * np.pi)**-0.5\n",
    "                        b = -(x - mean)**2 / (2 * var)\n",
    "                        \n",
    "                        p = a*np.exp(b)\n",
    "\n",
    "                    likelihood *= p\n",
    "\n",
    "                posterior = prior * likelihood\n",
    "                \n",
    "                if posterior > highest_posterior:\n",
    "                    most_likely_cls = cls\n",
    "                    highest_posterior = posterior\n",
    "            \n",
    "            if most_likely_cls is None:\n",
    "                \n",
    "                # This can easily happen when there is not much\n",
    "                # data, and some of the variances are 0.\n",
    "                # In this case, for lack of useful\n",
    "                # input, any estimate will do.\n",
    "                \n",
    "                # This does bias the model\n",
    "                # towards one class. I'm not sure what to\n",
    "                # do about that though.\n",
    "                \n",
    "                most_likely_cls = cls\n",
    "                \n",
    "                \n",
    "            predictions[i] = most_likely_cls\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # The assignment specified that there\n",
    "        # is no need to implement this.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for Testing and Comparison to Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep:\n",
    "\n",
    "  - Limit class values\n",
    "\n",
    "  - Convert to numerical\n",
    "  \n",
    "  - Train-test-split\n",
    "  \n",
    "  - Normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path, target_feature, allowed_classes=None, allowed_features=None):\n",
    "    \n",
    "    # Read in the data\n",
    "    \n",
    "    data = pd.read_csv(path, index_col = 0)\n",
    "    \n",
    "    # Only keep allowed classes\n",
    "    \n",
    "    if allowed_classes is not None:\n",
    "        data = data[data[target_feature].isin(allowed_classes)]\n",
    "        \n",
    "    if allowed_features is not None:\n",
    "        data = data[set([*allowed_features, target_feature])]\n",
    "        \n",
    "    # Convert nonnumeric columns to numeric columns\n",
    "\n",
    "    numeric_cols = list(data.select_dtypes(np.number).columns)\n",
    "    if target_feature in numeric_cols:\n",
    "        numeric_cols.remove(target_feature)\n",
    "        \n",
    "    nonnumeric_cols = list(set(data.columns) - set(numeric_cols))\n",
    "    if target_feature in nonnumeric_cols:\n",
    "        nonnumeric_cols.remove(target_feature)\n",
    " \n",
    "    numeric_data = pd.get_dummies(data, columns=nonnumeric_cols)\n",
    "    \n",
    "    encoder = sklearn.preprocessing.OrdinalEncoder()\n",
    "    numeric_data[[target_feature]] = encoder.fit_transform(numeric_data[[target_feature]])\n",
    "    \n",
    "    # normalization and train-test-splitting\n",
    "    \n",
    "    # Note that y is reshaped below from a column vector to a row vector.\n",
    "    # pandas yields a column, sklearn and my implementation expect a row.\n",
    "    \n",
    "    X = numeric_data.drop(target_feature, axis=1).values\n",
    "    y = numeric_data[[target_feature]].values.reshape(len(numeric_data))\n",
    "\n",
    "    test_size = 0.5\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=test_size)\n",
    "\n",
    "    # Also note that normalization is done AFTER train-test-splitting\n",
    "    # Preprocessing transformations should not depend on incoming\n",
    "    # data.\n",
    "    \n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    max_k = X_train.shape[1]\n",
    "    \n",
    "    return data, numeric_data, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_supplier, data):\n",
    "    \n",
    "    _, _, X_train, X_test, y_train, y_test = data\n",
    "    \n",
    "    model = model_supplier()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "def compare_models(data):\n",
    "    \n",
    "    print(\"SKLearn GNB:\", test_model(GaussianNB, data))\n",
    "    print(\"My GNB:\", test_model(MyGaussianNB, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Test with 2 datasets\n",
    "\n",
    "I tested with a variety of datasets. The two below are the \"submitted\" ones, and then later there is a cell with the results of the full set.\n",
    "\n",
    "Penguins and Diabetes give exactly the same for mine and sklearn's models, which is what we expect.\n",
    "\n",
    "There is an interesting difference when all the features for penguins are used - the score of mine stays much the same, but the score of the sklearn decreases by about 0.2, which is major. I don't know why. I looked at the sklearn source, and found that they did use logs for multiplying probabilities. They do actually use the log function, though, no shortcuts. Perhaps there are shortcuts elsewhere?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penguins\n",
    "\n",
    "The two work identically for this data set when the feature set is restricted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn GNB: 0.9626168224299065\n",
      "My GNB: 0.9626168224299065\n"
     ]
    }
   ],
   "source": [
    "compare_models(prep_data(\n",
    "    path=\"penguins_af.csv\", \n",
    "    target_feature=\"species\", \n",
    "    allowed_classes=['Adelie','Chinstrap'],\n",
    "    allowed_features=['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results:\n",
    "```\n",
    "SKLearn GNB: 0.9626168224299065\n",
    "My GNB: 0.9626168224299065\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when the features are not restricted, they no longer match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn GNB: 0.7383177570093458\n",
      "My GNB: 0.9532710280373832\n"
     ]
    }
   ],
   "source": [
    "compare_models(prep_data(\n",
    "    path=\"penguins_af.csv\", \n",
    "    target_feature=\"species\", \n",
    "    allowed_classes=['Adelie','Chinstrap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two work identically (with all features), which is what we expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn GNB: 0.7473958333333334\n",
      "My GNB: 0.7473958333333334\n"
     ]
    }
   ],
   "source": [
    "compare_models(prep_data(\n",
    "    path=\"diabetes.csv\", \n",
    "    target_feature=\"neg_pos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results:\n",
    "```\n",
    "SKLearn GNB: 0.7473958333333334\n",
    "My GNB: 0.7473958333333334\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Datasets\n",
    "\n",
    "I tested with some of the other datasets in the general data folder on brightspace.\n",
    "\n",
    "For almost all of them, the SKLearn and my implementations perform identically. \n",
    "\n",
    "For a few, my implementation scores better. (glass2, penguins, restaurant) <br>\n",
    "I don't know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplesPears.csv\n",
      "SKLearn GNB: 0.6\n",
      "My GNB: 0.6\n",
      "\n",
      "AthleteSelection.csv\n",
      "SKLearn GNB: 0.8\n",
      "My GNB: 0.7\n",
      "\n",
      "AthleteSelection1.csv\n",
      "SKLearn GNB: 0.8\n",
      "My GNB: 0.7\n",
      "\n",
      "diabetes.csv\n",
      "SKLearn GNB: 0.7473958333333334\n",
      "My GNB: 0.4869791666666667\n",
      "\n",
      "Forecast.csv\n",
      "SKLearn GNB: 0.7777777777777778\n",
      "My GNB: 0.7777777777777778\n",
      "\n",
      "glassV2.csv\n",
      "SKLearn GNB: 0.3592233009708738\n",
      "My GNB: 0.49514563106796117\n",
      "\n",
      "Household.csv\n",
      "SKLearn GNB: 0.0\n",
      "My GNB: 0.0\n",
      "\n",
      "MamMass.csv\n",
      "SKLearn GNB: 0.5550935550935551\n",
      "My GNB: 0.5821205821205822\n",
      "\n",
      "penguins_af.csv\n",
      "SKLearn GNB: 0.7544910179640718\n",
      "My GNB: 0.8982035928143712\n",
      "\n",
      "restaurant.csv\n",
      "SKLearn GNB: 0.3333333333333333\n",
      "My GNB: 0.5\n",
      "\n",
      "survival.csv\n",
      "SKLearn GNB: 0.7254901960784313\n",
      "My GNB: 0.45751633986928103\n",
      "\n",
      "Swimming.csv\n",
      "SKLearn GNB: 0.6\n",
      "My GNB: 0.6\n",
      "\n",
      "vehicle.csv\n",
      "SKLearn GNB: 0.42080378250591016\n",
      "My GNB: 0.42080378250591016\n",
      "\n",
      "wine.csv\n",
      "SKLearn GNB: 0.9662921348314607\n",
      "My GNB: 0.6966292134831461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "target_features = {\n",
    "    \"ApplesPears.csv\": \"Class\",\n",
    "    \"AthleteSelection.csv\": \"Selected\",\n",
    "    \"AthleteSelection1.csv\": \"Selected\",\n",
    "    \"diabetes.csv\": \"neg_pos\",\n",
    "    \"Forecast.csv\": \"Go-Out\",\n",
    "    \"glassV2.csv\": \"Type\",\n",
    "    \"Household.csv\": \"Category\",\n",
    "    \"MamMass.csv\": \"Severity\",\n",
    "    \"penguins_af.csv\": \"species\",\n",
    "    \"restaurant.csv\": \"WillWait?\",\n",
    "    \"survival.csv\": \"Class\",\n",
    "    \"Swimming.csv\": \"Swimming\",\n",
    "    \"vehicle.csv\": \"TYPE\",\n",
    "    \"wine.csv\": \"class\"\n",
    "}\n",
    "\n",
    "for path, target in target_features.items():\n",
    "    \n",
    "    print(path)\n",
    "    \n",
    "    if not os.path.isfile(path):\n",
    "        print(\"Cannot find file\")\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            compare_models(prep_data(path, target))\n",
    "        except:\n",
    "            # Don't bother printing details, just single\n",
    "            # it out the dataset for individual \n",
    "            # attention & debugging\n",
    "            print(\"ERROR\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "ApplesPears.csv\n",
    "SKLearn GNB: 0.6\n",
    "My GNB: 0.6\n",
    "\n",
    "AthleteSelection.csv\n",
    "SKLearn GNB: 0.8\n",
    "My GNB: 0.8\n",
    "\n",
    "AthleteSelection1.csv\n",
    "SKLearn GNB: 0.8\n",
    "My GNB: 0.8\n",
    "\n",
    "diabetes.csv\n",
    "SKLearn GNB: 0.7473958333333334\n",
    "My GNB: 0.7473958333333334\n",
    "\n",
    "Forecast.csv\n",
    "SKLearn GNB: 0.7777777777777778\n",
    "My GNB: 0.7777777777777778\n",
    "\n",
    "glassV2.csv\n",
    "SKLearn GNB: 0.3592233009708738\n",
    "My GNB: 0.6116504854368932\n",
    "\n",
    "Household.csv\n",
    "SKLearn GNB: 0.0\n",
    "My GNB: 0.0\n",
    "\n",
    "MamMass.csv\n",
    "SKLearn GNB: 0.5550935550935551\n",
    "My GNB: 0.6923076923076923\n",
    "\n",
    "penguins_af.csv\n",
    "SKLearn GNB: 0.7544910179640718\n",
    "My GNB: 0.9700598802395209\n",
    "\n",
    "restaurant.csv\n",
    "SKLearn GNB: 0.3333333333333333\n",
    "My GNB: 0.5\n",
    "\n",
    "survival.csv\n",
    "SKLearn GNB: 0.7254901960784313\n",
    "My GNB: 0.7254901960784313\n",
    "\n",
    "Swimming.csv\n",
    "SKLearn GNB: 0.6\n",
    "My GNB: 0.6\n",
    "\n",
    "vehicle.csv\n",
    "SKLearn GNB: 0.42080378250591016\n",
    "My GNB: 0.42080378250591016\n",
    "\n",
    "wine.csv\n",
    "SKLearn GNB: 0.9662921348314607\n",
    "My GNB: 0.9662921348314607\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

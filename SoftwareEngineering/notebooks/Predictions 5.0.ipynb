{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"...\"\n",
    "PORT = 3306\n",
    "NAME = \"...\"\n",
    "USER = \"...\"\n",
    "PASS = \"...\"\n",
    "\n",
    "CONNECTION_STRING = f\"mysql://{USER}:{PASS}@{URI}:{PORT}/{NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT DATE(date_time) as date, DAYOFWEEK(date_time) as day, CAST(date_time AS time) as time, HOUR(date_time) as hour, CAST(sunrise AS time) as sunrise, CAST(sunset as time) as sunset, main_description, wind_speed, ROUND(feels_like - 270) as temp\n",
    "FROM dublin_weather;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_sql(sql, connection)\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "workday = (1 < weather_data.day) & (weather_data.day < 7) * 1.0\n",
    "weather_data['is_workday'] = workday.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_yn = []\n",
    "for description in weather_data['main_description']:\n",
    "    rain_yn.append('rain' in description.lower())\n",
    "weather_data['rain_yn'] = rain_yn\n",
    "weather_data['rain_yn'] = weather_data['rain_yn'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['daytime'] = (weather_data.time > weather_data.sunrise) & (weather_data.time < weather_data.sunset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['morning-rush'] = (weather_data.hour >= 8) & (weather_data.hour < 10) & (weather_data.is_workday == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['evening-rush'] = (weather_data.hour >= 4) & (weather_data.hour < 7) & (weather_data.is_workday == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_model = weather_data.drop(['sunrise', 'sunset', 'time', 'day', 'main_description'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_numbers_sql = \"\"\"\n",
    "SELECT number\n",
    "FROM stations\n",
    "ORDER BY number ASC\"\"\"\n",
    "station_numbers = pd.read_sql(station_numbers_sql, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "data_for_models2 = {}\n",
    "\n",
    "for station_number in station_numbers['number']:\n",
    "    sql = f\"\"\"\n",
    "SELECT DATE(retrieved) as date, HOUR(retrieved) as hour, ROUND(avg(available_bikes)) as avg_available_bikes\n",
    "FROM station_update\n",
    "WHERE number = {station_number} \n",
    "GROUP BY HOUR(retrieved), DATE(retrieved)\"\"\"\n",
    "    station_target = pd.read_sql(sql, connection)\n",
    "    station_weather = pd.merge(weather_data, station_target, on=['date','hour'])\n",
    "    data_for_models2[station_number] = station_weather\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2nn_unnormed_models = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(df[['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]], df['avg_available_bikes'])\n",
    "    k2nn_unnormed_models[station_number] = neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_model = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X = df[['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y = df['avg_available_bikes']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predicted = neigh.predict(X_test)\n",
    "    test_2knn_model[station_number] = { \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_2knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test_2knn_normed_model = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X = df[['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y = df['avg_available_bikes']\n",
    "    \n",
    "    x = X.values\n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(x) \n",
    "    scaled = weather_scaler.transform(x)\n",
    "    X_normed=pd.DataFrame(scaled, columns=X.columns)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normed, y, test_size=0.3, random_state=1)\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predicted = neigh.predict(X_test)\n",
    "    results_test_2knn_normed_model[station_number] = { \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "results_test_2knn_normed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_2knn_model.items():\n",
    "    print(f\"\"\"Station {key}\n",
    "    Mean AE with normalisation: {value['Mean absolute error']}\\tMean AE without:[key]['Mean absolute error']}\n",
    "    Median AE with normalisation: {value['Median absolute error']}\\tMean AE without: {results_test_2knn_normed_model[key]['Median absolute error']}\n",
    "    R squared score with noram: {value['R squared score']}\\tR squared score without: {results_test_2knn_normed_model[key]['R squared score']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2nn_unnormed_models_with_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(df[['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]], df['avg_available_bikes'])\n",
    "    k2nn_unnormed_models_with_hour[station_number] = neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_unnormed_with_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X = df[['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y = df['avg_available_bikes']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predicted = neigh.predict(X_test)\n",
    "    test_2knn_models_unnormed_with_hour[station_number] = { \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_2knn_models_unnormed_with_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_unnormed_with_hour.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_model.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in results_test_2knn_normed_model.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-russia",
   "metadata": {},
   "source": [
    "Conclusion - normed without hour is most effective. Let's test it using everything until April 4th as training data and last week's data as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {}\n",
    "testing_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "split_date_str = '2021-04-04 23:00:00'\n",
    "split_date = datetime.datetime.strptime(split_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for key, df in data_for_models2.items():\n",
    "    training_data[key] = df.loc[df['date'] <= split_date.date()]\n",
    "    testing_data[key] = df.loc[df['date'] > split_date.date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_normed_without_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X_train = training_data[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train_scaled, y_train)\n",
    "    predicted = neigh.predict(X_test_scaled)\n",
    "    test_2knn_models_normed_without_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_2knn_models_normed_without_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_without_hour.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_normed_with_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X_train = training_data[station_number][['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data[station_number][['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train_scaled, y_train)\n",
    "    predicted = neigh.predict(X_test_scaled)\n",
    "    test_2knn_models_normed_with_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_2knn_models_normed_with_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_with_hour.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_not_normed_with_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X_train = training_data[station_number][['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data[station_number][['wind_speed', 'hour', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "#     weather_scaler = preprocessing.MinMaxScaler()\n",
    "#     weather_scaler.fit(X_train) \n",
    "#     X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "#     X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predicted = neigh.predict(X_test)\n",
    "    test_2knn_models_not_normed_with_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_with_hour.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_not_normed_without_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X_train = training_data[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data[station_number]['avg_available_bikes']\n",
    "    \n",
    "#     weather_scaler = preprocessing.MinMaxScaler()\n",
    "#     weather_scaler.fit(X_train) \n",
    "#     X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "#     X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predicted = neigh.predict(X_test)\n",
    "    test_2knn_models_not_normed_without_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_without_hour.items():\n",
    "    if item['R squared score'] < -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_without_hour.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_without_hour.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_with_hour.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_not_normed_with_hour.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_without_hour.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_without_hour.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_with_hour.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_with_hour.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data2 = {}\n",
    "testing_data2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date_str = '2021-04-07 23:00:00'\n",
    "split_date = datetime.datetime.strptime(split_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for key, df in data_for_models2.items():\n",
    "    training_data2[key] = df.loc[df['date'] <= split_date.date()]\n",
    "    testing_data2[key] = df.loc[df['date'] > split_date.date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2knn_models_normed_without_hour2 = {}\n",
    "for station_number in data_for_models2.keys():\n",
    "    X_train = training_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    neigh.fit(X_train_scaled, y_train)\n",
    "    predicted = neigh.predict(X_test_scaled)\n",
    "    test_2knn_models_normed_without_hour2[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_2knn_models_normed_without_hour2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_without_hour2.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-pharmacy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_2knn_models_normed_without_hour2.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_station = 2\n",
    "for key, item in test_2knn_models_normed_without_hour2.items():\n",
    "    if item['Median absolute error'] < test_2knn_models_normed_without_hour2[best_station]['Median absolute error']:\n",
    "        best_station = key\n",
    "        \n",
    "best_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_station = 2\n",
    "for key, item in test_2knn_models_normed_without_hour2.items():\n",
    "    if item['Median absolute error'] > test_2knn_models_normed_without_hour2[worst_station]['Median absolute error']:\n",
    "        worst_station = key\n",
    "        \n",
    "worst_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_v2_demo = {}\n",
    "for station_number in [6, 62]:\n",
    "    X_train = training_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    model = KNeighborsRegressor(n_neighbors=2)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models_v2_demo[station_number] = [model, weather_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_6 = {}\n",
    "demo_6['actual'] = testing_data2[6]['avg_available_bikes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = testing_data2[6][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "demo_6['predicted'] = models_v2_demo[6][0].predict(models_v2_demo[6][1].transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date_and_time = list(zip(testing_data2[6]['date'].values, testing_data2[6]['time'].values))\n",
    "x = []\n",
    "for date_time in date_and_time:\n",
    "    x.append(np.datetime64(date_time[0]) + date_time[1])\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "plt.plot(x,demo_6['actual'], label='Actual')\n",
    "plt.plot(x,demo_6['predicted'],label='Predicted')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.ylabel('number of bikes')\n",
    "plt.title('Actual and predicted bike availability with k=2 for station 6, April 8 - 11 (inclusive)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('station6k2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-study",
   "metadata": {},
   "source": [
    "Repeat for worst station...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_62 = {}\n",
    "demo_62['actual'] = testing_data2[62]['avg_available_bikes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_62 = testing_data2[62][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "demo_62['predicted'] = models_v2_demo[62][0].predict(models_v2_demo[62][1].transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_62['time'] = testing_data2[62]['hour'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "plt.plot(x, demo_62['actual'], label='Actual')\n",
    "plt.plot(x, demo_62['predicted'],label='Predicted')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.ylabel('number of bikes')\n",
    "plt.xlabel('hour')\n",
    "plt.title('Actual and predicted bike availability with k=2 for station 62, April 8 - 11 (inclusive)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('station62k2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_v3_demo = {}\n",
    "for station_number in [6, 62]:\n",
    "    X_train = training_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models_v3_demo[station_number] = [model, weather_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_6_v2 = {}\n",
    "demo_6_v2['actual'] = testing_data2[6]['avg_available_bikes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_2 = testing_data2[6][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "demo_6_v2['predicted'] = models_v3_demo[6][0].predict(models_v3_demo[6][1].transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "date_and_time = list(zip(testing_data2[6]['date'].values, testing_data2[6]['time'].values))\n",
    "x = []\n",
    "for date_time in date_and_time:\n",
    "    x.append(np.datetime64(date_time[0]) + date_time[1])\n",
    "\n",
    "plt.plot(x, demo_6_v2['actual'], label='Actual')\n",
    "plt.plot(x, demo_6_v2['predicted'],label='Predicted')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.ylabel('number of bikes')\n",
    "plt.xlabel('date')\n",
    "plt.title('Actual and predicted bike availability for station 6 with k=5, April 8 - 11 (inclusive)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('station6k5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_62_v2 = {}\n",
    "demo_62_v2['actual'] = testing_data2[62]['avg_available_bikes'].values\n",
    "x_test_62_v2 = testing_data2[62][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "demo_62_v2['predicted'] = models_v3_demo[62][0].predict(models_v3_demo[62][1].transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "plt.plot(x, demo_62_v2['actual'], label='Actual')\n",
    "plt.plot(x, demo_62_v2['predicted'],label='Predicted')\n",
    "\n",
    "plt.ylabel('number of bikes')\n",
    "plt.title('Actual and predicted bike availability with k=5 for station 62, April 8 - 11 (inclusive)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('station62k5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_5knn_models_normed_without_hour = {}\n",
    "for station_number in data_for_models2.keys():\n",
    "    X_train = training_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_train = training_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    X_test = testing_data2[station_number][['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y_test = testing_data2[station_number]['avg_available_bikes']\n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor()\n",
    "    neigh.fit(X_train_scaled, y_train)\n",
    "    predicted = neigh.predict(X_test_scaled)\n",
    "    test_5knn_models_normed_without_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_5knn_models_normed_without_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_5knn_models_normed_without_hour.items():\n",
    "    if item['Median absolute error'] <= 3:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key, item in test_5knn_models_normed_without_hour.items():\n",
    "    if item['Median absolute error'] >= 5:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average median absolute error\n",
    "total = 0\n",
    "for key, results in test_5knn_models_normed_without_hour.items():\n",
    "    total += results['Median absolute error']\n",
    "av = total / 109\n",
    "av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_split_5knn_models_normed_without_hour = {}\n",
    "for station_number, df in data_for_models2.items():\n",
    "    X = df[['wind_speed', 'temp', 'is_workday', 'rain_yn', 'daytime', 'morning-rush', 'evening-rush',]]\n",
    "    y = df['avg_available_bikes']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1) \n",
    "    \n",
    "    weather_scaler = preprocessing.MinMaxScaler()\n",
    "    weather_scaler.fit(X_train) \n",
    "    X_train_scaled=pd.DataFrame(weather_scaler.transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    X_test_scaled=pd.DataFrame(weather_scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    neigh = KNeighborsRegressor()\n",
    "    neigh.fit(X_train_scaled, y_train)\n",
    "    predicted = neigh.predict(X_test_scaled)\n",
    "    test_train_split_5knn_models_normed_without_hour[station_number] = { \n",
    "                                    \"Mean absolute error\": mean_absolute_error(predicted, y_test),\n",
    "                                      \"Median absolute error\": median_absolute_error(predicted, y_test),\n",
    "                                      \"R squared score\": r2_score(predicted, y_test)}\n",
    "    \n",
    "test_train_split_5knn_models_normed_without_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for key, results in test_train_split_5knn_models_normed_without_hour.items():\n",
    "    total += results['Median absolute error']\n",
    "av = total / 109\n",
    "av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-audience",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

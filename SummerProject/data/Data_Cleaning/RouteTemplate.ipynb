{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required packages\n",
    "import scipy\n",
    "#Import package pandas for data analysis\n",
    "import pandas as pd\n",
    "\n",
    "#Import package numpy for numeric computing\n",
    "import numpy as np\n",
    "\n",
    "#Import package matplotlib for visualisation/plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import package seaborn for visualisation\n",
    "import seaborn as sns\n",
    "\n",
    "#For showing plots directly in the notebook run the command below\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from pandas import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from time import gmtime\n",
    "from time import strftime\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in feather file\n",
    "df = pd.read_feather(\"MasterCleanedLeaving&TripsDataCombined.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get df of route 16 only\n",
    "df_16 = df.loc[df['LineID'] == '16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get route 16 in direction 1 only\n",
    "df_16_1 = df_16.loc[df_16['Direction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16[df_16['Direction']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1 = df_16_1.sort_values(by=['TRIPID', 'DAYOFSERVICE','PROGRNUMBER'], ascending = [False,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for row in df_16_1['DayOfService']:\n",
    "    list.append(row)\n",
    "    \n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1.ProgrNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops = df_16_1['PROGRNUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops = np.array(priorstops[:-1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual arrival time of prior stopid\n",
    "priorstops_actualTime_Arr = df_16_1['ACTUALTIME_ARR']\n",
    "priorstops_actualTime_Arr = np.array(priorstops_actualTime_Arr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops_actualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops_actualTime_Arr = np.insert(priorstops_actualTime_Arr, 0, priorstops_actualTime_Arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorstops_actualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['priorstops_actualTime_Arr'] = priorstops_actualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['JourneyTime'] = df_16_1['ACTUALTIME_DEP'] - df_16_1['priorstops_actualTime_Arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['JourneyTime'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualTime_Arr = []\n",
    "\n",
    "for row in df_16_1['ACTUALTIME_ARR']:\n",
    "    time = strftime(\"%H:%M:%S\", gmtime(row))\n",
    "    actualTime_Arr.append(time)\n",
    "            \n",
    "actualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['ACTUALTIME_ARR'] = actualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualTime_Dep = []\n",
    "\n",
    "for row in df_16_1['ACTUALTIME_DEP']:\n",
    "    time = strftime(\"%H:%M:%S\", gmtime(row))\n",
    "    actualTime_Dep.append(time)\n",
    "            \n",
    "actualTime_Dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['ACTUALTIME_DEP'] = actualTime_Dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlannedTime_Arr = []\n",
    "\n",
    "for row in df_16_1['PLANNEDTIME_ARR']:\n",
    "    time = strftime(\"%H:%M:%S\", gmtime(row))\n",
    "    PlannedTime_Arr.append(time)\n",
    "            \n",
    "PlannedTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['PLANNEDTIME_ARR'] = PlannedTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlannedTime_Dep = []\n",
    "\n",
    "for row in df_16_1['PLANNEDTIME_DEP']:\n",
    "    time = strftime(\"%H:%M:%S\", gmtime(row))\n",
    "    PlannedTime_Dep.append(time)\n",
    "            \n",
    "PlannedTime_Dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['PLANNEDTIME_DEP'] = PlannedTime_Dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorStopsActualTime_Arr = []\n",
    "\n",
    "for row in df_16_1['priorstops_actualTime_Arr']:\n",
    "    time = strftime(\"%H:%M:%S\", gmtime(row))\n",
    "    priorStopsActualTime_Arr.append(time)\n",
    "            \n",
    "priorStopsActualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['priorstops_actualTime_Arr'] = priorStopsActualTime_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['Month'] = df_16_1['DayOfService'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['Day'] = df_16_1['DayOfService'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['Hour'] = df_16_1['ACTUALTIME_ARR'].apply(pd.to_datetime).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_School = []\n",
    "\n",
    "for row in df_16_1['Month']:\n",
    "    if row == 6 or row == 7 or row== 8:\n",
    "        list_School.append('0')\n",
    "    else:\n",
    "        list_School.append('1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['School']=list_School "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rushHour = []\n",
    "\n",
    "for row in df_16_1['ACTUALTIME_DEP']:\n",
    "    if row >= '07:00:00' and row <= '08:30:00' or row >= '16:00:00' and row <= '18:00:00':\n",
    "        list_rushHour.append('1')\n",
    "    else:\n",
    "        list_rushHour.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['RushHour']=list_rushHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_weekend = []\n",
    "\n",
    "for row in df_16_1['Day']:\n",
    "    if row == '5' or row == '6':\n",
    "        list_weekend.append('1')\n",
    "    else:\n",
    "        list_weekend.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['Weekend'] = list_weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = ['2018/01/01', '2018/03/17', '2018/04/02', '2018/05/07','2018/06/04', '2018/08/06', '2018/10/29', '2018/12/25', '2018/12/26']\n",
    "\n",
    "# for holiday in holidays:\n",
    "#     list_dfHolidays = []\n",
    "#     for row in df['DayOfService']:\n",
    "#         print(row.date())\n",
    "#         if row.date() == holiday.date():\n",
    "#             print('true')\n",
    "# #             list_dfHolidays.append('1')           \n",
    "#         else:\n",
    "# #             list_dfHolidays.append('0')\n",
    "#             print('false')\n",
    "newHolidays = []\n",
    "for holiday in holidays:\n",
    "    newHolidays.append(datetime.datetime.strptime(holiday,\"%Y/%m/%d\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newhols1 = []\n",
    "\n",
    "for holiday in newHolidays:\n",
    "      newhols1.append(holiday.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfHols = []\n",
    "for row in df_16_1['DAYOFSERVICE']:\n",
    "#         print(row.date())\n",
    "    if row.date() == datetime.date(2018, 1, 1) or row.date() == datetime.date(2018, 3, 17) or row.date() == datetime.date(2018, 4, 2) or row.date() == datetime.date(2018, 5, 7) or row.date() == datetime.date(2018, 6, 4) or row.date() == datetime.date(2018, 8, 6) or row.date() == datetime.date(2018, 10, 29) or row.date() ==  datetime.date(2018, 12, 25) or row.date() == datetime.date(2018, 12, 26):\n",
    "#             print('true')\n",
    "        list_dfHols.append('1')           \n",
    "    else:\n",
    "        list_dfHols.append('0')\n",
    "#             print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['Holiday'] = list_dfHols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1 = df_16_1[(df_16_1['JourneyTime'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1.to_csv('df_16_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historic_weather():\n",
    "    engine = create_engine('mysql+mysqlconnector://team17:123456@telemachus.ucd.ie:3336/dublinbus', echo = True)\n",
    "    historic_weather = pd.read_sql(\"SELECT * FROM dublinbus.FullHourlyWeather2018;\", engine)\n",
    "    return historic_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = historic_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Hour'] = weather.weather_date.apply(pd.to_datetime).dt.hour\n",
    "weather['DayOfService'] = weather.weather_date.apply(pd.to_datetime).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['rain'] = weather['rain'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16_1['ProgrNumber']=df_16_1['ProgrNumber'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['DayOfService'] = weather['DayOfService'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in weather['weather_date']:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherCombined_df = pd.merge(df_16_1,\n",
    "                 weather,\n",
    "                 on=['Hour', 'DayOfService'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherCombined_df = WeatherCombined_df[(WeatherCombined_df['JourneyTime'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherCombined_df.drop(columns = ['dewpt','vappr','rhum','msl','wddir','ww','w','sun','clht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=WeatherCombined_df[\"JourneyTime\"]\n",
    "X=WeatherCombined_df.drop([\"JourneyTime\",\"Holiday\", \"index\", \"DayOfService\",'dewpt','vappr','rhum','msl','wddir','ww','w','sun','clht', 'ProgrNumber','PROGRNUMBER','TRIPID', 'TripID', 'LineID', 'weather_date','priorstops_actualTime_Arr','PLANNEDTIME_ARR', 'PLANNEDTIME_DEP','ACTUALTIME_ARR','ACTUALTIME_DEP', 'VEHICLEID', 'DAYOFSERVICE', 'RouteID', 'School', 'RushHour', 'Weekend', 'Direction'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherCombined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WeatherCombined_df['RushHour'] = WeatherCombined_df['RushHour'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherCombined_df = WeatherCombined_df[(WeatherCombined_df['JourneyTime'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = X.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['STOPPOINTID'] = X['STOPPOINTID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_columns:\n",
    "    X[column]=X[column].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randForestModel = RandomForestRegressor(n_estimators = 10, random_state=10)\n",
    "randForestModel.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predictionTest = randForestModel.predict(X_test)\n",
    "forestScore = r2_score(y_test, predictionTest)\n",
    "forestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeRegressor()\n",
    "decisionTree.fit(X_train, y_train)\n",
    "predictions = decisionTree.predict(X_test)\n",
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors = 10)\n",
    "knn_model.fit(X_train, y_train.values.ravel())\n",
    "knnTest = knn_model.predict(X_test)\n",
    "knnScore = r2_score(y_test, knnTest)\n",
    "knnScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test = linearModel.predict(X_test)\n",
    "linear_score = r2_score(y_test, linear_test)\n",
    "linear_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestPrediction = randForestModel.predict([[1631, 12, 9, 16, 0.2, 9.5, 7.8, 13, 25000, 7]])\n",
    "forestPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randForestModel = RandomForestRegressor(n_estimators = 10, random_state=10)\n",
    "randForestModel.fit(X_train, y_train.values.ravel())\n",
    "pickle.dump(randForestModel, open(f'randForest_16_1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_test =  metrics.mean_absolute_error(y_test, predictionTest)\n",
    "MSE_test =  metrics.mean_squared_error(y_test, predictionTest)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, predictionTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = decisionTree.predict([[7349, 12, 9, 16, 0.2, 9.5, 7.8, 13, 25000, 7]])\n",
    "prediction_values = prediction[0]\n",
    "print(f\"Predicted journey available: {prediction_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = X\n",
    "feature_imp = pd.Series(randForestModel.feature_importances_, index=feature_list)\n",
    "feature_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel = LinearRegression()\n",
    "linearModel.fit(X_train, y_train)\n",
    "linear_prediction = linearModel.predict([[1632, 12, 9, 16, 0.2, 9.5, 7.8, 13, 25000, 7]])\n",
    "linear_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric=X_train.columns[(X_train.dtypes==\"int64\") | (X_train.dtypes==\"float64\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=pd.concat([X_train[numeric], y], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.title(\"Pearson's Correlation of numerical Features for Route 16, direction 1\")\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidth=.5,cmap=\"YlGnBu\")\n",
    "plt.savefig(\"PearsonsCorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel = LinearRegression()\n",
    "linearModel.fit(X_train, y_train)\n",
    "linear_prediction = linearModel.predict([[1127, 12, 9, 16, 0.2, 9.5, 7.8, 13, 25000, 7]])\n",
    "linear_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = X.columns\n",
    "feature_imp = pd.Series(randForestModel.feature_importances_, index=feature_list)\n",
    "feature_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(route, direction, stop1, stop2):\n",
    "    df = pd.read_csv('df_'+ str(route) + '_'+ str(direction)+'.csv')\n",
    "    #get all stops in the various routes but have them in order\n",
    "    stops = df['STOPPOINTID']\n",
    "    indices=[]\n",
    "    output = []\n",
    "    stopIDs = [stop1,stop2]\n",
    "    allStops = []\n",
    "    total = 0\n",
    "    \n",
    "    #get all bus stops in route 16, direction 1\n",
    "    for stop in stops:\n",
    "        allStops.append(stop)\n",
    "     \n",
    "   #get unique bus stops so we don't get duplicate stops, impportant to keep them in order  \n",
    "    for x in allStops:\n",
    "        if x not in output:\n",
    "            output.append(x)\n",
    "    \n",
    "    #get index of chosen bus stops in list of bus stops\n",
    "    for stop in stopIDs:\n",
    "        index_number = output.index(stop)\n",
    "        index_number += 1\n",
    "        indices.append(index_number)\n",
    "#     print(indices)\n",
    "    #use slicing to get the bus stops on the chosen journey\n",
    "    slice = output[indices[0]:indices[1]]\n",
    "#     print(slice)\n",
    "    \n",
    "    #get predicted journey time of all stops and add them together to get overall journey time\n",
    "    for stop in slice:\n",
    "        forest_prediction = pickle.load(open(f'randForest_'+str(route)+'_'+str(direction)+'.pkl', 'rb'))\n",
    "        prediction = forest_prediction.predict([[stop, 12, 9, 16, 0.2, 9.5, 7.8, 13, 25000, 7]])\n",
    "        total += forestPrediction \n",
    "    print(\"Prediction in seconds:\",total)\n",
    "        \n",
    "    \n",
    "\n",
    "getPrediction(16,1,3669,1632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
